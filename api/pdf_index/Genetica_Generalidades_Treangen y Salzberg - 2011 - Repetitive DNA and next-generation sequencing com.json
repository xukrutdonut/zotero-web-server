{
  "pdfPath": "/home/arkantu/Documentos/Zotero Biblioteca/Genetica/Generalidades/Treangen y Salzberg - 2011 - Repetitive DNA and next-generation sequencing com.pdf",
  "fileName": "Treangen y Salzberg - 2011 - Repetitive DNA and next-generation sequencing com.pdf",
  "relativePath": "Genetica/Generalidades/Treangen y Salzberg - 2011 - Repetitive DNA and next-generation sequencing com.pdf",
  "text": "NIH Public Access\n                            Author Manuscript\n                            Nat Rev Genet. Author manuscript; available in PMC 2013 January 1.\n                           Published in final edited form as:\nNIH-PA Author Manuscript\n\n\n\n\n                            Nat Rev Genet. ; 13(1): 36–46. doi:10.1038/nrg3117.\n\n\n\n                           Repetitive DNA and next-generation sequencing: computational\n                           challenges and solutions\n                           Todd J. Treangen1 and Steven L. Salzberg1,2\n                           1McKusick–Nathans Institute for Genetic Medicine, Johns Hopkins University School of Medicine,\n\n                           Baltimore, Maryland 21205, USA\n                           2Department of Biostatistics, Johns Hopkins Bloomberg School of Public Health, Baltimore,\n\n                           Maryland 21205, USA\n\n                           Abstract\n                                Repetitive DNA sequences are abundant in a broad range of species, from bacteria to mammals,\n                                and they cover nearly half of the human genome. Repeats have always presented technical\nNIH-PA Author Manuscript\n\n\n\n\n                                challenges for sequence alignment and assembly programs. Next-generation sequencing projects,\n                                with their short read lengths and high data volumes, have made these challenges more difficult.\n                                From a computational perspective, repeats create ambiguities in alignment and assembly, which,\n                                in turn, can produce biases and errors when interpreting results. Simply ignoring repeats is not an\n                                option, as this creates problems of its own and may mean that important biological phenomena are\n                                missed. We discuss the computational problems surrounding repeats and describe strategies used\n                                by current bioinformatics systems to solve them.\n\n                                            DNA sequencing efficiency has increased by approximately 100,000-fold in the decade\n                                            since sequencing of the human genome was completed. Next-generation sequencing (NGS)\n                                            machines can now sequence the entire human genome in a few days, and this capability has\n                                            inspired a flood of new projects that are aimed at sequencing the genomes of thousands of\n                                            individual humans and a broad swath of animal and plant species1-3. New methods, such as\n                                            whole-transcriptome sequencing (also called RNA sequencing (RNA-seq))4-7, chromatin\n                                            immunoprecipitation followed by sequencing (ChIP–seq)8-11 and sequencing to identify\n                                            methylated DNA (methyl-seq)12,13, are transforming our ability to capture an accurate\n                                            picture of the molecular processes within the cell, which, in turn, is leading to a better\n                                            understanding of human diseases14. Whole-genome resequencing combined with new,\nNIH-PA Author Manuscript\n\n\n\n\n                                            highly efficient alignment software is being used to discover large numbers of SNPs and\n                                            structural variants in previously sequenced genomes15. In response to this influx of new\n                                            laboratory methods, many novel computational tools have been developed to map NGS\n                                            reads to genomes and to reconstruct genomes and transcriptomes11,16-22. Current NGS\n                                            platforms produce shorter reads than Sanger sequencing (NGS reads are 50–150 bp), but\n                                            with vastly greater numbers of reads, as many as 6 billion per run. By contrast, the original\n                                            human genome project generated approximately 30 million reads using Sanger sequencing.\n\n                                            Some of the biggest technical challenges that are associated with these new methods are\n                                            caused by repetitive DNA23: that is, sequences that are similar or identical to sequences\n                                            elsewhere in the genome. Most large genomes are filled with repetitive sequences; for\n\n\n                           © 2012 Macmillan Publishers Limited. All rights reserved\n                           Correspondence to S.L.S. salzberg@jhu.edu.\n                           Competing interests statement\n                           The authors declare no competing financial interests.\n\f                           Treangen and Salzberg                                                                                       Page 2\n\n\n                                               example, nearly half of the human genome is covered by repeats, many of which have been\n                                               known about for decades24,25. Although some repeats appear to be nonfunctional, others\n                                               have played a part in human evolution26,27, at times creating novel functions, but also acting\nNIH-PA Author Manuscript\n\n\n\n\n                                               as independent, ‘selfish’ sequence elements28,29. Repeats arise from a variety of biological\n                                               mechanisms that result in extra copies of a sequence being produced and inserted into the\n                                               genome. Repeats come in all shapes and sizes: they can be widely interspersed repeats,\n                                               tandem repeats or nested repeats, they may comprise just two copies or millions of copies,\n                                               and they can range in size from 1–2 bases (mono- and dinucleotide repeats) to millions of\n                                               bases. Well-characterized repeats in the human genome (BOX 1) are sometimes separated\n                                               into two classes: short tandem repeats (also called microsatellites) and longer interspersed\n                                               repeats (called short interspersed nuclear elements (SINEs) and long interspersed nuclear\n                                               elements (LINEs)). The most well-documented example of interspersed repeats in the\n                                               human genome is the class of Alu repeat elements, which cover approximately 11% of the\n                                               genome25. Repeats can also take the form of large-scale segmental duplications, such as\n                                               those found on some human chromosomes30 and even whole-genome duplication, such as\n                                               the duplication of the Arabidopsis thaliana genome31. High levels of repetitiveness are\n                                               found across all kingdoms of life, and plant genomes contain particularly high proportions\n                                               of repeats: for example, transposable elements cover >80% of the maize genome32. A recent\n                                               study reported that the short-lived fish Nothobranchius furzeri has 21% of its genome\n                                               occupied by tandem repeats, suggesting a possible role for tandem repeats in the ageing\n                                               process33. Even bacterial genomes can exhibit repeat content up to 40%, as demonstrated by\nNIH-PA Author Manuscript\n\n\n\n\n                                               Orientia tsutsugamushi34.\n\n                                               From a computational perspective, repeats create ambiguities in alignment and in genome\n                                               assembly, which, in turn, can produce errors when interpreting results. Repeats that are\n                                               sufficiently divergent do not present problems, so for the remaining discussion in this\n                                               Review, we define a repeat as a sequence that is at least 100 bp in length, that occurs two or\n                                               more times in the genome and that exhibits >97% identity to at least one other copy of itself.\n                                               This definition excludes many repetitive sequences, but it includes those that present the\n                                               principal computational challenges.\n\n                                               In this Review, we consider the challenges that are posed by repeats for genome\n                                               resequencing projects, de novo genome assembly and RNA-seq analysis. We focus on two\n                                               classes of computational tools: software for the alignment of NGS reads and software for the\n                                               assembly of genomes and transcriptomes. Some of the more widely used programs in both\n                                               categories are shown in TABLES 1,2, which illustrates the breadth of tools available. Rather\n                                               than describing the algorithmic details of these programs, we will discuss their shared\n                                               strategies for solving repeat-induced analysis problems in each situation and address some\n                                               of their limitations.\nNIH-PA Author Manuscript\n\n\n\n\n                              Genome resequencing projects\n                                               Genome resequencing allows researchers to study genetic variation by analysing many\n                                               genomes from the same or from closely related species23,35-37. The primary requirement is\n                                               for a high-quality reference genome onto which all of the short NGS reads can be mapped.\n                                               After sequencing a sample to deep coverage, it is possible to detect SNPs, copy number\n                                               variants (CNVs) and other types of sequence variation without the need for de novo\n                                               assembly. The computational task involves aligning millions or billions of reads back to the\n                                               reference genome using one of several short-read alignment programs (TABLE 1). The two\n                                               most efficient of these aligners, Bowtie and the Burrows–Wheeler Aligner (BWA), achieve\n                                               throughputs of 10–40 million reads per hour on a single computer processor. In spite of this\n                                               recent progress, a major challenge remains when trying to decide what to do with reads that\n\n\n\n                                                   Nat Rev Genet. Author manuscript; available in PMC 2013 January 1.\n\f                           Treangen and Salzberg                                                                                        Page 3\n\n\n                                               map to multiple locations (that is, multi-reads). Below, we discuss how current short-read\n                                               alignment tools handle these reads and what problems remain unresolved.\nNIH-PA Author Manuscript\n\n\n\n\n                              Problems when mapping multi-reads\n                                               For computational tools that align NGS reads to a genome, the most commonly encountered\n                                               problem arises when reads align to multiple locations. For convenience, these reads that map\n                                               to multiple locations are often called multi-reads. Although the specific type of repeat does\n                                               not directly influence the read-mapping program, it can influence downstream analyses\n                                               (such as SNP calling) that rely on unique regions that flank the repeats. The percentage of\n                                               short reads (25 bp or longer) that map to a unique location on the human genome is typically\n                                               reported to be 70–80%, although this number varies depending on the read length, the\n                                               availability of paired-end reads and the sensitivity of the software used for alignment. The\n                                               repeat content in the human genome, by contrast, is around 50%. The main reason for the\n                                               discrepancy is that most repeats are inexact, which means that many reads will have a\n                                               unique ‘best match’, even though the same sequence might occur with slight variations in\n                                               other locations (FIG. 1a). Assigning reads to the location of their best alignment is the\n                                               simplest way to resolve repeats, although it is not always correct.\n\n                                               For example, suppose that a read maps to two locations, A and B, where the read aligns with\n                                               one mismatch at location A and with one deletion at B (FIG. 1b). If the alignment program\n                                               considers a mismatch to be less ‘costly’ than a gap (that is, if it assumes that substitutions\nNIH-PA Author Manuscript\n\n\n\n\n                                               are more likely than deletions), then the aligner will put the read in location A. However, if\n                                               the source DNA has a true deletion in location B, then the read would perfectly match\n                                               position B. This illustrates a problem that is inherent in the process of aligning reads to a\n                                               reference genome: the source DNA is virtually never identical to the reference (and, in fact,\n                                               the differences are the whole reason why the source is being sequenced).\n\n                                               Another example to consider is the following. Suppose that a human genome sample is\n                                               sequenced, but only analysis of the variants that are present in part of the genome is\n                                               required: for example, analysis of chromosome 14. The most straightforward approach\n                                               would be to use a short-read aligner to map reads directly to that chromosome.\n                                               Unfortunately, this strategy would lead to a large pile up of reads from repetitive regions,\n                                               because all reads from those repeats would have to go to the same chromosome. To avoid\n                                               this bias, we must map the reads against the entire genome and use a strategy of random\n                                               placement of multi-reads to scatter them uniformly across all repeat copies. TABLE 1 lists\n                                               some of the most useful parameters for dealing with repeats within the most popular\n                                               alignment programs.\n\n                              Multi-read mapping strategies\nNIH-PA Author Manuscript\n\n\n\n\n                                               Systematic alignment of reads to incorrect positions in the genome can lead to false\n                                               inferences of SNPs and CNVs. For example, FIG. 1b illustrates how a SNP would be\n                                               erroneously identified after a mistake by the alignment program. Essentially, an algorithm\n                                               has three choices for dealing with multi-reads38 (FIG. 2). The first is to ignore them,\n                                               meaning that all multi-reads are discarded. The second option is the best match approach, in\n                                               which the alignment with the fewest mismatches is reported. If there are multiple, equally\n                                               good best match alignments, then an aligner will either choose one at random or report all of\n                                               them. The third choice is to report all alignments up to a maximum number, d, regardless of\n                                               the total number of alignments found. A variant on this strategy is to ignore multi-reads that\n                                               align to >d locations.\n\n                                               To simplify the analysis, some alignment protocols prefer the ‘ignore’ strategy for multi-\n                                               reads. However, this strategy limits analysis to unique regions in the genome, discarding\n\n\n                                                   Nat Rev Genet. Author manuscript; available in PMC 2013 January 1.\n\f                           Treangen and Salzberg                                                                                         Page 4\n\n\n                                               many multi-gene families as well as all repeats, which might result in biologically important\n                                               variants being missed. An example in which this occurred is a recent study of retinitis\n                                               pigmentosa, wherein Tucker et al.39 performed exome sequencing of induced pluripotent\nNIH-PA Author Manuscript\n\n\n\n\n                                               stem cells that were derived from a patient with autosomal recessive retinitis pigmentosa.\n                                               They discovered that the cause of the disease in this patient was a novel, homozygous\n                                               insertion of a 353 bp Alu repeat in the middle of exon 9 of male germ-cell-associated kinase\n                                               (MAK). The software used for aligning the reads to the genome trimmed off Alu sequences\n                                               from the ends of reads, which created a MAK gene that appeared to be normal and initially\n                                               prevented the discovery of the mutation. Only through a fortunate accident did the\n                                               investigators discover the presence of the Alu insertion39. The two alternative strategies\n                                               listed above will ‘fill in’ repetitive regions, although only the best match approach will\n                                               provide a reasonable estimate of coverage (FIG. 2b). Allowing multi-reads to map to all\n                                               possible positions (FIG. 2c) avoids making a possibly erroneous choice about read\n                                               placement. Multi-reads can sometimes be manually resolved with tools such as IGV40 and\n                                               SAMtools41, which allow users to choose which read placements to keep and which to\n                                               discard. However, this is not usually a feasible strategy for very large NGS data sets.\n\n                              Genotyping and SNP detection\n                                               After mapping the reads, the next step in the computational pipeline is to call SNPs using a\n                                               program such as GATK42, MAQ43, SAMtools41, SOAPsnp44 or VarScan45. If multi-reads\n                                               are handled using the ‘best match’ alignment method, SNPs should be found in at least some\nNIH-PA Author Manuscript\n\n\n\n\n                                               repetitive regions. Some methods attempt to handle multi-reads more explicitly. For\n                                               example, Sniper38 assumes that some multi-reads will align unambiguously owing to slight\n                                               sequence variations, and it also assumes that SNPs will occur in different locations in\n                                               different paralogous genes. It uses these assumptions to compute an alignment probability\n                                               for each multi-read. The probability is computed using a Bayesian genotyping model that\n                                               decomposes the likehood of a read mapping to a given locus into its component likelihoods.\n                                               This strategy offers some help for repeats that have few copies, but computation of these\n                                               probabilities comes at a cost: Sniper would require ~3 central processing unit months to\n                                               analyse data for a 70-fold coverage of the human genome.\n\n                              Structural and copy number variant detection\n                                               Computational tools can discover multiple types of variants in NGS data, including\n                                               deletions, insertions, inversions, translocations and duplications (reviewed in REF. 23).\n                                               Although the software methods that are available can find variants in unique regions\n                                               reliably, the short NGS read lengths prevent them from detecting variation in repetitive\n                                               regions with comparable sensitivity. When repeats are longer than the length of a read,\n                                               methods must rely on depth of coverage or paired-end data to determine whether a repeat\nNIH-PA Author Manuscript\n\n\n\n\n                                               region is a variant — neither of these options provides a perfect indictation of structural and\n                                               CNVs. For example, suppose that a genome of interest is sequenced to an average depth of\n                                               30-fold coverage but that a particular tandem repeat that has two copies in the reference\n                                               genome has 60-fold coverage. These data suggest that the tandem repeat has four copies in\n                                               the genome of interest — twice the number seen in the reference. However, depth of\n                                               coverage varies across a genome, which makes it difficult to distinguish N versus N + 1\n                                               copies of a repeat with high confidence.\n\n                                               With this caveat, one of the first algorithms to incorporate both read-depth and read-pair\n                                               data for accurate CNV discovery was VariationHunter13, which has been updated to allow it\n                                               to find transposons46. Recently, He et al.47 described a new method that was designed to\n                                               find CNVs even in repeat-rich regions; this method also used information from read pairs\n                                               and depth of coverage. These authors attempt to account for all mappings of each multi-\n\n\n\n                                                   Nat Rev Genet. Author manuscript; available in PMC 2013 January 1.\n\f                           Treangen and Salzberg                                                                                         Page 5\n\n\n                                               read, and their method uses this information to improve the estimation of the true copy\n                                               number of each repeat.\nNIH-PA Author Manuscript\n\n\n\n\n                                               In general, the mapping strategies used for resequencing projects apply to any NGS\n                                               application in which reads need to be mapped to a reference genome, although some\n                                               customizations are needed to address the demands of particular applications. For example, in\n                                               a methyl-seq experiment, analysis is customized to account for C-to-T changes.\n\n                              De novo genome assembly\n                                               Genome assembly algorithms begin with a set of reads and attempt to reconstruct a genome\n                                               as completely as possible without introducing errors. NGS read lengths (50–150 bp) are\n                                               considerably shorter than the 800–900 bp lengths that capillary-based (Sanger) sequencing\n                                               methods were achieving more than 5 years ago, and these short read lengths make assembly\n                                               more difficult. NGS technology generates higher depth of coverage at far lower cost than\n                                               Sanger sequencing and, as a result, current strategies for assembly attempt to use deeper\n                                               coverage to compensate for shorter reads. However, repetitive sequences create substantial\n                                               difficulties that coverage depth cannot always overcome.\n\n                              Problems caused by repeats\n                                               For de novo assembly, repeats that are longer than the read length create gaps in the\nNIH-PA Author Manuscript\n\n\n\n\n                                               assembly. This fact, coupled with the short length of NGS sequences, means that most\n                                               recent genome assemblies are much more fragmented than assemblies from a few years ago,\n                                               as evidenced by recent surveys48,49. In addition to creating gaps, repeats can be erroneously\n                                               collapsed on top of one another and can cause complex, misassembled rearrangements50,51.\n                                               The degree of difficulty (in terms of correctness and contiguity) that repeats cause during\n                                               genome assembly largely depends on the read length: if a species has a common repeat of\n                                               length N, then assembly of the genome of that species will be far better if read lengths are\n                                               longer than N. As illustrated in BOX 1, the human genome has millions of copies of repeats\n                                               in the range of 200–500 bp, which is longer than the reads that are produced by today’s most\n                                               efficient NGS technologies. Until read lengths are greater than 500 bp, assemblies of large\n                                               plant and animal genomes will need to use other strategies to assemble these types of repeats\n                                               correctly. Even Sanger read lengths (800–900 bp) cannot resolve longer repeats such as\n                                               LINEs (BOX 1), and these will continue to require long-range linking information (or\n                                               exceptionally long-range reads, perhaps generated by future technologies) if they are to be\n                                               resolved.\n\n                                               Despite these challenges, many new de novo assemblers have emerged to tackle this\n                                               problem, a selection of which are shown in TABLE 1. All of these assemblers fall into one\nNIH-PA Author Manuscript\n\n\n\n\n                                               of two classes: overlap-based assemblers and de Bruijn graph assemblers, both of which\n                                               create graphs (of different types) from the read data. The algorithms then traverse these\n                                               graphs in order to reconstruct the genome. From a technical perspective, repeats cause\n                                               branches in these graphs, and assemblers must then make a guess as to which branch to\n                                               follow (FIG. 3). Incorrect guesses create false joins (chimeric contigs) and erroneous copy\n                                               numbers. If the assembler is more conservative, it will break the assembly at these branch\n                                               points, leading to an accurate but fragmented assembly with fairly small contigs.\n\n                                               The essential problem with repeats is that an assembler cannot distinguish them, which\n                                               means that the regions flanking them can easily be misassembled. The most common error is\n                                               that an assembler will create a chimaera by joining two chromosomal regions that do not\n                                               belong near one another, as illustrated in FIG. 3. As shown in the figure, all of the reads may\n                                               align well to the misassembled genome; the only hint of a problem is found in the paired-\n                                               end links. Paired-end reads are generated from a single DNA fragment of a fixed size, from\n\n\n                                                   Nat Rev Genet. Author manuscript; available in PMC 2013 January 1.\n\f                           Treangen and Salzberg                                                                                          Page 6\n\n\n                                               which both ends are sequenced. An assembler uses both the expected distance and the\n                                               orientation of the reads when reconstructing a genome. If the sequence data do not contain\n                                               paired ends that span a particular repeat, then it might be impossible to assemble the data\nNIH-PA Author Manuscript\n\n\n\n\n                                               unambiguously.\n\n                                               Two recent studies illustrate the difficulty of assembling large genomes from very short\n                                               reads. Alkan et al.52 looked at recent human genome assemblies and found that they were\n                                               16% shorter than the reference genome, primarily owing to missing repetitive sequences. In\n                                               particular, the NGS assemblies were lacking 420 Mbp of common repeats, including LINE 1\n                                               elements, Alu elements and a large majority of segmental duplications. Ye et al.48 compared\n                                               two NGS assemblies of the chicken genome to its reference genome, which was generated\n                                               by Sanger sequencing. The chicken genome has a much lower repeat content than the human\n                                               genome (10% versus 50%), making it considerably easier to assemble. Although their\n                                               analysis did not look at recent segmental duplications at the level of detail of Alkan et al.,\n                                               they found only 37 long (>10 kb) contigs that were misassembled in total from the two\n                                               assemblies. Visual inspection indicated that most of these errors were caused by the collapse\n                                               of interspersed repeats flanking unique sequences (FIG. 3c).\n\n                                               Tandem repeats present another common assembly problem. Near-identical tandem repeats\n                                               are often collapsed into fewer copies, and it is difficult for an assembler to determine the\n                                               true copy number. Notably, the investigation into the 2001 Bacillus anthracis attacks in the\nNIH-PA Author Manuscript\n\n\n\n\n                                               United States identified isolates of the attack strain that only differed in the presence of two-\n                                               and three-copy tandem repeats, which the genome assembler had initially collapsed\n                                               incorrectly53,54. After the assembly errors were detected, the CNVs were correctly\n                                               reconstructed. These CNVs were present in only minor ‘morphotypes’ from the anthrax-\n                                               containing letters, which contained a mixture of slight variants on the Ames strain of B.\n                                               anthracis. The tandem repeat copies were 822, 2,023 and 2,607 nucleotides in length, and\n                                               these unique markers provided crucial forensic evidence that led investigators back to a\n                                               single source for the attacks53. FIGURE 3b illustrates a collapsed repeat in which two\n                                               identical copies are assembled into one. Note that all of the reads may align perfectly, but\n                                               the coverage depth and the mate-pair information will be inconsistent.\n\n                              Strategies for handing repeats\n                                               In either an overlap graph or a de Bruijn graph, all copies of a repeat will initially be\n                                               represented by a single node. Repeat boundaries and sequencing errors show up as branch\n                                               points in the graph, and complex repeats appear as densely connected ‘tangles’ (REF. 55).\n                                               Assemblers use two main strategies to resolve these tangles. First and most importantly, they\n                                               use mate-pair information from reads that were sequenced in pairs. A variety of protocols\n                                               are available for producing two reads from opposite ends of a longer fragment of DNA;\nNIH-PA Author Manuscript\n\n\n\n\n                                               these fragments range in length from 200 bp up to 20,000 bp. Even longer stretches can be\n                                               produced using fosmid clones (30 to 40 kbp) and bacterial artificial chromosome (BAC)\n                                               clones (up to 150 kbp), although efficient ways of sequencing the ends of these clones are\n                                               still under development. If a read pair spans a repeat, then the assembler can use that\n                                               information to decide how to move from a unique region in the graph through a repeat node\n                                               and into the correct unique region on the other side. Longer fragments allow assemblers to\n                                               span longer repeats. Because paired-end information is imperfect, most assemblers require\n                                               two or more pairs of reads to confirm each decision about how to assemble a repeat region.\n\n                                               A good illustration of this strategy is the recently assembled potato genome56. Potato is\n                                               highly repetitive and has repeats covering an estimated 62% of its genome. The first\n                                               assembly of this 844 Mbp genome, which was generated with a combination of Illumina and\n                                               454 reads, produced tiny contigs that had an N50 size of just 697 bp and also produced\n                                               scaffolds with an N50 size of 8 kb. As the genome was reassembled using Illumina mate-\n\n\n                                                   Nat Rev Genet. Author manuscript; available in PMC 2013 January 1.\n\f                           Treangen and Salzberg                                                                                        Page 7\n\n\n                                               pair libraries with increasingly large fragment sizes (2 to 10 kb), the scaffolds grew linearly\n                                               with the insert size, as shown in FIG. 4. The final scaffold N50 size, after using Sanger\n                                               sequencing to generate paired ends from 40 kb fosmids and 100 kb BACs, was 1.3 Mbp — a\nNIH-PA Author Manuscript\n\n\n\n\n                                               100-fold improvement over the initial statistics. This is a good example of how long\n                                               fragment libraries can be used to ‘jump’ across repetitive DNA and link together many more\n                                               contigs.\n\n                                               The second main strategy for handling repeats is to compute statistics on the depth of\n                                               coverage for each contig. These statistics do not tell assemblers exactly how to assemble\n                                               each repeat, but they do identify the repeats themselves. In order to make use of this\n                                               information, assembly programs must assume that the genome is uniformly covered; this\n                                               means that if a genome is sequenced to 50-fold (50×) coverage, then the assembler assumes\n                                               that most contigs should also be covered at 50×. A repetitive region, by contrast, will have\n                                               substantially deeper coverage, which allows the algorithm to identify it as a repeat and to\n                                               process it differently. In particular, repeats are usually assembled after unique regions, and\n                                               assemblers may require multiple paired ends to link a repetitive contig to a unique one. One\n                                               recent study57 suggested that paired-end libraries can be ‘tuned’ to the specific genome\n                                               being assembled; in it, a strategy is described that uses a preliminary sequence assembly\n                                               from unpaired reads to estimate repeat structure, which, in turn, can be used to design\n                                               appropriate paired-end libraries.\nNIH-PA Author Manuscript\n\n\n\n\n                                               A combination of strategies exists for resolving problems that are caused by repetitive DNA,\n                                               including sequencing strategies that use fragment libraries of varying sizes57, post-\n                                               processing software that is designed for detecting misassemblies51, analysing coverage\n                                               statistics and detecting and resolving tangles in a de Bruijn graph. One of the leading NGS\n                                               assemblers, Allpaths-LG, has specific requirements for the types of paired-end reads that it\n                                               needs for optimal performance20. None of these requirements completely solves the\n                                               problems, however, and the ultimate solution may require much longer read lengths.\n\n                              Alignment and assembly of RNA sequences\n                                               High-throughput sequencing of the transcriptome provides a detailed picture of the genes\n                                               that are expressed in a cell. RNA-seq experiments capture a huge dynamic range of\n                                               expression levels, and they also detect novel transcripts and alternative splicing events. In\n                                               response to the rapid growth of these experiments, many new computational tools have\n                                               emerged, some of which are shown in TABLE 1. RNA-seq analysis centres around three\n                                               main computational tasks: mapping the reads to a reference genome, assembling the reads\n                                               into full-length or partial transcripts and quantifying the amount of each transcript. Above,\n                                               we discussed the first two tasks in the context of genome resequencing projects and de novo\nNIH-PA Author Manuscript\n\n\n\n\n                                               assembly, and the problems caused by repeats are largely the same in transcriptome\n                                               assembly and alignment.\n\n                              Splicing\n                                               A distinct challenge posed by RNA-seq data is the need for spliced alignment of NGS reads.\n                                               Simply put, this is the problem of aligning a read to two physically separate locations on the\n                                               genome, which is made necessary by the presence of introns. RNA-seq aligners, such as\n                                               TopHat58, MapSplice59, rnaSeqMap60, RUM61 and SpliceMap62 are capable of aligning a\n                                               short read to two distinct locations. Other aligners, including TopHat-Fusion63,\n                                               FusionSeq64, ShortFuse65 and SplitSeek61 have been designed to scan RNA-seq data and to\n                                               detect fusion genes that are caused by chromosome breakage and rejoining: a common event\n                                               in cancer cells. Because a read must be split into pieces before alignment, spliced alignments\n                                               are shorter, which, in turn, means that repeats present a greater problem than in full-length\n\n\n\n                                                   Nat Rev Genet. Author manuscript; available in PMC 2013 January 1.\n\f                           Treangen and Salzberg                                                                                         Page 8\n\n\n                                               alignments. For example, if an intron interrupts a read so that only 5 bp of that read span the\n                                               splice site, then there may be many equally good locations to align the short 5 bp fragment.\nNIH-PA Author Manuscript\n\n\n\n\n                                               Spliced alignment algorithms address this problem by requiring additional, confirming\n                                               alignments in which longer sequences align on both sides of each splice site. This strategy\n                                               works well for alignments that span normal genes but, for fusion genes, repeats are\n                                               particularly problematic. Fusion gene discovery algorithms must allow a pair of reads to\n                                               align anywhere in the genome; this means that the normal constraints on the distance and\n                                               orientation of a mate pair cannot be used. When one of the reads falls in a repeat sequence,\n                                               the algorithm may be faced with thousands of false positives. Collectively, this becomes\n                                               millions of false positives when extended to all of the data from an RNA-seq experiment.\n                                               Most fusion gene aligners address this problem by excluding any read with more than one\n                                               alignment, although some allow a small, fixed number of alignments. Without this\n                                               restriction, algorithms for fusion gene detection might become computationally unfeasible.\n\n                              Gene expression\n                                               Another challenge that is unique to RNA-seq data is the measurement of gene expression\n                                               levels, which can be estimated from the number of reads mapping to each gene. The\n                                               standard approach for estimating expression levels is to count the number of reads or read\n                                               pairs (also known as fragments) that are aligned to a given gene and to normalize the count\n                                               based on gene length and sequencing depth. (The measurement is usually expressed as reads\nNIH-PA Author Manuscript\n\n\n\n\n                                               or fragments per kilobase of transcript per million reads or fragments sequenced,\n                                               abbreviated as RPKM or FPKM.)\n\n                                               For gene families and genes containing repeat elements (BOX 1), multi-reads can introduce\n                                               errors in estimates of gene expression. For example, suppose that a gene exists in two\n                                               slightly different copies, A and B, and suppose that A is expressed at a much higher level\n                                               than B is expressed. If the genes are very close paralogues, then most of the reads will map\n                                               equally well to either copy. In regions where A and B diverge, reads will preferentially map\n                                               to the correct version of the gene, but this might only be a small portion of the total\n                                               transcript. Thus, the overall estimate of expression of A will be biased downwards, and the\n                                               estimate of expression of B will be biased upwards. This error will increase as the sequence\n                                               similarity between A and B increases.\n\n                                               One way to avoid this bias in the placement of multi-reads is the strategy implemented in\n                                               ERANGE5 and related methods: these approaches distribute multi-reads in proportion to the\n                                               number of reads that map to unique regions of each transcript. A similar idea was developed\n                                               into a more sophisticated statistical model by Jiang and Wong66, who used it to allocate\n                                               reads among different splice variants. A method that was developed by Chung et al.67 also\nNIH-PA Author Manuscript\n\n\n\n\n                                               places multi-reads proportionally, after first estimating expression levels using an\n                                               expectation maximization algorithm. They demonstrated that, in contrast to methods that\n                                               only considered uniquely mapped reads, their method can markedly increase coverage in\n                                               ChIP–seq data, which, in turn, allows for detection of signals that would otherwise be\n                                               missed67. Li et al.68 developed a software tool called RNA-seq by Expectation\n                                               Maximization (RSEM) to address the uncertainty that is inherent in multi-read mapping by\n                                               modelling both isoform levels and non-un",
  "wordCount": 9609,
  "indexed": "2025-09-25T22:40:16.321Z",
  "method": "direct"
}
